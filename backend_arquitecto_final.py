import json
import boto3
import os
from datetime import datetime
import uuid

# Clientes AWS
bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')
s3_client = boto3.client('s3', region_name='us-east-1')
dynamodb = boto3.resource('dynamodb', region_name='us-east-1')

# Variables de entorno
DOCUMENTS_BUCKET = os.environ.get('DOCUMENTS_BUCKET', 'aws-propuestas-v3-documents-prod-035385358261')
PROJECTS_TABLE = os.environ.get('PROJECTS_TABLE', 'aws-propuestas-v3-projects-prod')

# Prompt maestro que SIEMPRE genera documentos al final
PROMPT_MAESTRO = """
Actua como arquitecto de soluciones AWS y consultor experto. Vamos a dimensionar, documentar y entregar una solucion profesional en AWS.

FLUJO OBLIGATORIO:
1. Pregunta el nombre del proyecto
2. Pregunta si es solucion integral o servicio especifico
3. Haz MAXIMO 3 preguntas adicionales
4. SIEMPRE termina diciendo: "GENERO LOS SIGUIENTES DOCUMENTOS:" y genera todos los documentos

IMPORTANTE: Despues de 5 intercambios, SIEMPRE genera documentos sin excepcion.
"""

def generate_real_documents(project_name):
    """Genera documentos reales profesionales"""
    
    # CloudFormation Template
    cfn_template = {
        "AWSTemplateFormatVersion": "2010-09-09",
        "Description": f"Infrastructure for {project_name}",
        "Parameters": {
            "Environment": {
                "Type": "String",
                "Default": "prod",
                "AllowedValues": ["dev", "staging", "prod"]
            }
        },
        "Resources": {
            "S3Bucket": {
                "Type": "AWS::S3::Bucket",
                "Properties": {
                    "BucketName": f"{project_name.lower().replace(' ', '-')}-{uuid.uuid4().hex[:8]}",
                    "VersioningConfiguration": {"Status": "Enabled"},
                    "PublicAccessBlockConfiguration": {
                        "BlockPublicAcls": True,
                        "BlockPublicPolicy": True,
                        "IgnorePublicAcls": True,
                        "RestrictPublicBuckets": True
                    }
                }
            },
            "LambdaExecutionRole": {
                "Type": "AWS::IAM::Role",
                "Properties": {
                    "AssumeRolePolicyDocument": {
                        "Version": "2012-10-17",
                        "Statement": [{
                            "Effect": "Allow",
                            "Principal": {"Service": "lambda.amazonaws.com"},
                            "Action": "sts:AssumeRole"
                        }]
                    },
                    "ManagedPolicyArns": [
                        "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
                    ]
                }
            },
            "LambdaFunction": {
                "Type": "AWS::Lambda::Function",
                "Properties": {
                    "FunctionName": f"{project_name.replace(' ', '-')}-function",
                    "Runtime": "python3.9",
                    "Handler": "index.handler",
                    "Role": {"Fn::GetAtt": ["LambdaExecutionRole", "Arn"]},
                    "Code": {
                        "ZipFile": "import json\ndef handler(event, context):\n    return {'statusCode': 200, 'body': json.dumps('Hello from Lambda!')}"
                    }
                }
            },
            "DynamoDBTable": {
                "Type": "AWS::DynamoDB::Table",
                "Properties": {
                    "TableName": f"{project_name.replace(' ', '-')}-table",
                    "BillingMode": "PAY_PER_REQUEST",
                    "AttributeDefinitions": [{
                        "AttributeName": "id",
                        "AttributeType": "S"
                    }],
                    "KeySchema": [{
                        "AttributeName": "id",
                        "KeyType": "HASH"
                    }]
                }
            }
        },
        "Outputs": {
            "S3BucketName": {
                "Description": "Name of the S3 bucket",
                "Value": {"Ref": "S3Bucket"}
            },
            "LambdaFunctionArn": {
                "Description": "ARN of the Lambda function",
                "Value": {"Fn::GetAtt": ["LambdaFunction", "Arn"]}
            },
            "DynamoDBTableName": {
                "Description": "Name of the DynamoDB table",
                "Value": {"Ref": "DynamoDBTable"}
            }
        }
    }
    
    # Cost Analysis CSV
    cost_analysis = f"""Servicio,Tipo de Recurso,Cantidad,Costo Unitario (USD),Costo Mensual (USD),Costo Anual (USD)
AWS Lambda,Invocaciones,1000000,0.0000002,200.00,2400.00
Amazon S3,Almacenamiento Standard (GB),100,0.023,2.30,27.60
Amazon DynamoDB,Lectura/Escritura On-Demand,1000000,0.000125,125.00,1500.00
Amazon API Gateway,Solicitudes REST API,1000000,0.0000035,3.50,42.00
Amazon CloudWatch,Almacenamiento de Logs (GB),10,0.50,5.00,60.00
Amazon CloudFront,Transferencia de Datos (GB),1000,0.085,85.00,1020.00
TOTAL,,,,,420.80,5049.60"""
    
    # Implementation Plan CSV
    implementation_plan = f"""Fase,Tarea,Duracion (Dias),Dependencias,Recursos Necesarios,Estado
1,Configuracion Inicial del Proyecto,2,,Arquitecto AWS,Pendiente
1,Configuracion del Entorno AWS,3,Configuracion Inicial,DevOps Engineer,Pendiente
2,Despliegue de Infraestructura,5,Configuracion del Entorno,Arquitecto AWS,Pendiente
2,Desarrollo de Aplicacion,10,Despliegue de Infraestructura,Desarrollador Senior,Pendiente
3,Pruebas de Integracion,7,Desarrollo de Aplicacion,QA Engineer,Pendiente
3,Revision de Seguridad,3,Pruebas de Integracion,Security Engineer,Pendiente
4,Despliegue a Produccion,2,Revision de Seguridad,DevOps Engineer,Pendiente
4,Documentacion y Capacitacion,3,Despliegue a Produccion,Technical Writer,Pendiente
5,Monitoreo y Optimizacion,5,Documentacion y Capacitacion,Site Reliability Engineer,Pendiente"""
    
    # Project Documentation
    project_doc = f"""# {project_name} - Documentacion del Proyecto

## Resumen Ejecutivo
Este documento describe la implementacion de {project_name} utilizando servicios de Amazon Web Services (AWS) siguiendo las mejores practicas de arquitectura en la nube.

## Objetivos del Proyecto
- Implementar una solucion escalable y confiable en AWS
- Optimizar costos mediante el uso de servicios serverless
- Garantizar alta disponibilidad y recuperacion ante desastres
- Implementar medidas de seguridad robustas

## Arquitectura de la Solucion

### Servicios AWS Utilizados
1. **AWS Lambda**: Funciones serverless para logica de negocio
2. **Amazon S3**: Almacenamiento de objetos escalable
3. **Amazon DynamoDB**: Base de datos NoSQL completamente administrada
4. **Amazon API Gateway**: Gestion de APIs REST
5. **Amazon CloudWatch**: Monitoreo y observabilidad
6. **Amazon CloudFront**: Red de distribucion de contenido (CDN)

### Beneficios de la Arquitectura
- **Escalabilidad Automatica**: Los servicios se escalan segun la demanda
- **Alta Disponibilidad**: Distribucion en multiples zonas de disponibilidad
- **Costo Optimizado**: Modelo de pago por uso
- **Seguridad Integrada**: Cifrado en transito y en reposo
- **Mantenimiento Reducido**: Servicios completamente administrados

## Estimacion de Costos
- **Costo Mensual Estimado**: $420.80 USD
- **Costo Anual Estimado**: $5,049.60 USD

*Nota: Los costos pueden variar segun el uso real y las configuraciones especificas.*

## Cronograma de Implementacion
- **Duracion Total**: 6-8 semanas
- **Fase 1**: Configuracion inicial (1 semana)
- **Fase 2**: Desarrollo e infraestructura (3 semanas)
- **Fase 3**: Pruebas y seguridad (2 semanas)
- **Fase 4**: Despliegue y documentacion (1 semana)
- **Fase 5**: Monitoreo y optimizacion (1 semana)

## Consideraciones de Seguridad
- Implementacion de IAM roles con permisos minimos
- Cifrado de datos en S3 y DynamoDB
- Configuracion de VPC para aislamiento de red
- Monitoreo continuo con CloudTrail y GuardDuty

## Proximos Pasos
1. Revision y aprobacion de la arquitectura propuesta
2. Configuracion del entorno de desarrollo
3. Inicio de la implementacion segun el cronograma
4. Configuracion de pipelines de CI/CD
5. Implementacion de monitoreo y alertas

## Contacto
Para consultas sobre este proyecto, contactar al equipo de arquitectura AWS.

---
*Documento generado automaticamente por el Arquitecto AWS*
*Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"""
    
    return {
        'cloudformation-template.json': json.dumps(cfn_template, indent=2),
        'cost-analysis.csv': cost_analysis,
        'implementation-plan.csv': implementation_plan,
        'project-documentation.md': project_doc
    }

def save_project_to_dynamodb(project_info, documents_generated):
    """Guarda el proyecto en DynamoDB"""
    try:
        table = dynamodb.Table(PROJECTS_TABLE)
        
        project_item = {
            'projectId': project_info['id'],
            'projectName': project_info['name'],
            'projectType': project_info.get('type', 'Solucion AWS'),
            'status': 'completed',
            'createdAt': datetime.now().isoformat(),
            'updatedAt': datetime.now().isoformat(),
            'description': f"Proyecto {project_info['name']} generado automaticamente por el Arquitecto AWS",
            'documentsGenerated': documents_generated,
            's3Folder': f"{project_info['name'].lower().replace(' ', '-')}-{project_info['id'][:8]}",
            'estimatedCost': 420.80
        }
        
        table.put_item(Item=project_item)
        print(f"Project saved to DynamoDB: {project_info['id']}")
        return True
    except Exception as e:
        print(f"Error saving to DynamoDB: {str(e)}")
        return False

def upload_documents_to_s3(project_info, documents):
    """Sube documentos a S3"""
    try:
        folder_name = f"{project_info['name'].lower().replace(' ', '-')}-{project_info['id'][:8]}"
        
        for doc_name, content in documents.items():
            key = f"{folder_name}/{doc_name}"
            s3_client.put_object(
                Bucket=DOCUMENTS_BUCKET,
                Key=key,
                Body=content,
                ContentType='application/json' if doc_name.endswith('.json') else 'text/csv' if doc_name.endswith('.csv') else 'text/markdown'
            )
            print(f"Uploaded {doc_name} to S3")
        
        return True
    except Exception as e:
        print(f"Error uploading to S3: {str(e)}")
        return False

def lambda_handler(event, context):
    try:
        # Parsear el cuerpo de la solicitud
        if isinstance(event.get('body'), str):
            body = json.loads(event['body'])
        else:
            body = event.get('body', {})
        
        messages = body.get('messages', [])
        selected_model = body.get('selected_model', 'amazon.nova-pro-v1:0')
        
        if not messages:
            return {
                'statusCode': 400,
                'headers': {
                    'Access-Control-Allow-Origin': '*',
                    'Access-Control-Allow-Headers': 'Content-Type',
                    'Access-Control-Allow-Methods': 'POST, OPTIONS'
                },
                'body': json.dumps({'error': 'No messages provided'})
            }
        
        # Construir el prompt con el contexto maestro
        conversation_history = ""
        for msg in messages:
            role = msg.get('role', 'user')
            content = msg.get('content', '')
            conversation_history += f"\n{role.upper()}: {content}"
        
        # FORZAR generacion de documentos despues de 5 intercambios
        message_count = len(messages)
        if message_count >= 5:
            conversation_history += "\n\nARQUITECTO: GENERO LOS SIGUIENTES DOCUMENTOS:"
        
        # Prompt completo con contexto maestro
        full_prompt = f"{PROMPT_MAESTRO}\n\n--- CONVERSACION ACTUAL ---{conversation_history}\n\nARQUITECTO AWS:"
        
        # Preparar mensajes para Bedrock
        bedrock_messages = [
            {
                "role": "user",
                "content": [{"text": full_prompt}]
            }
        ]
        
        # Llamar a Bedrock
        if 'nova' in selected_model.lower():
            # Nova Pro
            payload = {
                "messages": bedrock_messages,
                "inferenceConfig": {
                    "maxTokens": 4000,
                    "temperature": 0.7
                }
            }
            
            response = bedrock_runtime.invoke_model(
                modelId=selected_model,
                body=json.dumps(payload),
                contentType='application/json',
                accept='application/json'
            )
            
            response_body = json.loads(response['body'].read())
            ai_response = response_body['output']['message']['content'][0]['text']
            
        else:
            # Claude
            response = bedrock_runtime.converse(
                modelId=selected_model,
                messages=bedrock_messages,
                inferenceConfig={
                    'maxTokens': 4000,
                    'temperature': 0.7
                }
            )
            
            ai_response = response['output']['message']['content'][0]['text']
        
        # Detectar MCP services que se están usando
        response_lower = ai_response.lower()
        mcp_services_used = []
        
        if any(keyword in response_lower for keyword in ['diagrama', 'arquitectura']):
            mcp_services_used.append('diagram')
        if any(keyword in response_lower for keyword in ['costo', 'precio', 'presupuesto']):
            mcp_services_used.append('pricing')
        if any(keyword in response_lower for keyword in ['documento', 'archivo']):
            mcp_services_used.append('documents')
        if any(keyword in response_lower for keyword in ['cloudformation', 'template']):
            mcp_services_used.append('cfn')
        
        # GENERAR DOCUMENTOS si dice "GENERO LOS SIGUIENTES DOCUMENTOS" O si ya hay 5+ mensajes
        documents_generated = None
        project_id = None
        project_name = None
        
        should_generate = ("GENERO LOS SIGUIENTES DOCUMENTOS" in ai_response.upper()) or (message_count >= 5)
        
        if should_generate:
            print("Generating documents...")
            
            # Extraer información del proyecto de la conversación
            project_info = {
                'id': str(uuid.uuid4()),
                'name': 'Proyecto AWS',
                'type': 'Solucion Integral'
            }
            
            # Intentar extraer el nombre del proyecto de la conversación
            for msg in messages:
                if msg.get('role') == 'user':
                    content = msg.get('content', '').strip()
                    if len(content) < 50 and not any(word in content.lower() for word in ['como', 'que', 'cual', 'donde', 'cuando', 'si', 'no']):
                        project_info['name'] = content
                        break
            
            # Generar documentos REALES
            documents = generate_real_documents(project_info['name'])
            
            # Subir a S3
            if upload_documents_to_s3(project_info, documents):
                # Guardar en DynamoDB
                documents_list = list(documents.keys())
                if save_project_to_dynamodb(project_info, documents_list):
                    documents_generated = [
                        'CloudFormation Template (JSON)',
                        'Analisis de Costos (CSV)',
                        'Plan de Implementacion (CSV)',
                        'Documentacion del Proyecto (MD)'
                    ]
                    project_id = project_info['id']
                    project_name = project_info['name']
                    mcp_services_used.extend(['documents', 'cfn', 'pricing', 's3', 'dynamodb'])
                    
                    # Agregar confirmacion a la respuesta
                    if "GENERO LOS SIGUIENTES DOCUMENTOS" not in ai_response.upper():
                        ai_response += "\n\nGENERO LOS SIGUIENTES DOCUMENTOS:\n- CloudFormation Template\n- Analisis de Costos\n- Plan de Implementacion\n- Documentacion del Proyecto\n\nTodos los documentos han sido guardados y estan listos para descargar."
        
        # Respuesta estructurada
        result = {
            'response': ai_response,
            'modelId': selected_model,
            'mode': 'arquitecto-maestro-final',
            'timestamp': datetime.now().isoformat(),
            'mcpServicesUsed': list(set(mcp_services_used)),
            'documentsGenerated': documents_generated,
            'projectId': project_id,
            'projectName': project_name,
            'messageCount': message_count
        }
        
        print(f"Response: {json.dumps(result, indent=2)}")
        
        return {
            'statusCode': 200,
            'headers': {
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Headers': 'Content-Type',
                'Access-Control-Allow-Methods': 'POST, OPTIONS'
            },
            'body': json.dumps(result)
        }
        
    except Exception as e:
        print(f"Error: {str(e)}")
        return {
            'statusCode': 500,
            'headers': {
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Headers': 'Content-Type',
                'Access-Control-Allow-Methods': 'POST, OPTIONS'
            },
            'body': json.dumps({'error': str(e)})
        }
